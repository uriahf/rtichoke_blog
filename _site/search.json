[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "ROC for SVM Model from ISLR\n\n\n\n\n\n\nROC\n\n\nPerformance Data\n\n\nISLR\n\n\nReplications\n\n\nyardstick\n\n\nGareth James\n\n\nDaniela Witten\n\n\nTrevor Hastie\n\n\nRob Tibshirani\n\n\n\n\n\n\n\n\n\nOct 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nDCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers\n\n\n\n\n\n\nReplications\n\n\nDecision\n\n\nEmily Vertosick\n\n\nAndrew Vickers\n\n\ndcurves\n\n\nrms\n\n\nHmisc\n\n\n\n\n\n\n\n\n\nSep 18, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nPrecision Recall from Feature Engineering by Max Kuhn and Kjell Johnson\n\n\n\n\n\n\nReplications\n\n\nROC\n\n\nPrecision Recall\n\n\nMax Kuhn\n\n\nKjell Johnson\n\n\nFeature Engineering by Max Kuhn and Kjell Johnson\n\n\nyardstick\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nBox-Cox transformation from Feature Engineering by Max Kuhn and Kjell Johnson\n\n\n\n\n\n\nReplications\n\n\nROC\n\n\nMax Kuhn\n\n\nKjell Johnson\n\n\nFeature Engineering by Max Kuhn and Kjell Johnson\n\n\ncaret\n\n\n\n\n\n\n\n\n\nAug 21, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-10-02-ROC-for-SVM/index.html",
    "href": "posts/2022-10-02-ROC-for-SVM/index.html",
    "title": "ROC for SVM Model from ISLR",
    "section": "",
    "text": "The following example of Support Vector Machine is taken from Introduction to Statistical Learning: a great introductory book to Data Science by Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani.\nThe original code is taken from ISLR tidymodels labs by Emil Hvitfeldt."
  },
  {
    "objectID": "posts/2022-10-02-ROC-for-SVM/index.html#introduction-to-statistical-learning-with-tidy-models",
    "href": "posts/2022-10-02-ROC-for-SVM/index.html#introduction-to-statistical-learning-with-tidy-models",
    "title": "ROC for SVM Model from ISLR",
    "section": "",
    "text": "The following example of Support Vector Machine is taken from Introduction to Statistical Learning: a great introductory book to Data Science by Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani.\nThe original code is taken from ISLR tidymodels labs by Emil Hvitfeldt."
  },
  {
    "objectID": "posts/2022-10-02-ROC-for-SVM/index.html#simulating-the-data",
    "href": "posts/2022-10-02-ROC-for-SVM/index.html#simulating-the-data",
    "title": "ROC for SVM Model from ISLR",
    "section": "Simulating the Data",
    "text": "Simulating the Data\n\nlibrary(tidymodels)\nlibrary(dplyr)\n\nset.seed(1)\n\nsim_data2 &lt;- tibble(\n  x1 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),\n  x2 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),\n  y  = factor(rep(c(1, 2), c(150, 50)))\n)\n\nset.seed(2)\n\nsim_data2_test &lt;- tibble(\n  x1 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),\n  x2 = rnorm(200) + rep(c(2, -2, 0), c(100, 50, 50)),\n  y  = factor(rep(c(1, 2), c(150, 50)))\n)"
  },
  {
    "objectID": "posts/2022-10-02-ROC-for-SVM/index.html#fitting-support-vector-machine-model",
    "href": "posts/2022-10-02-ROC-for-SVM/index.html#fitting-support-vector-machine-model",
    "title": "ROC for SVM Model from ISLR",
    "section": "Fitting Support Vector Machine Model",
    "text": "Fitting Support Vector Machine Model\n\nsvm_rbf_spec &lt;- svm_rbf() |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"kernlab\")\n\nsvm_rbf_fit &lt;- svm_rbf_spec |&gt;\n  fit(y ~ ., data = sim_data2)"
  },
  {
    "objectID": "posts/2022-10-02-ROC-for-SVM/index.html#performance-data",
    "href": "posts/2022-10-02-ROC-for-SVM/index.html#performance-data",
    "title": "ROC for SVM Model from ISLR",
    "section": "Performance Data",
    "text": "Performance Data\n\nyardstickrtichoke\n\n\n\nyardstick_roc &lt;- augment(svm_rbf_fit, new_data = sim_data2_test) |&gt;\n  roc_curve(truth = y, estimate = .pred_1)\n\nyardstick_roc \n\n# A tibble: 202 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1  -Inf           0                1\n 2     0.0763      0                1\n 3     0.0799      0.0200           1\n 4     0.0854      0.0400           1\n 5     0.0961      0.0600           1\n 6     0.0991      0.0800           1\n 7     0.101       0.1              1\n 8     0.104       0.12             1\n 9     0.107       0.14             1\n10     0.108       0.16             1\n# ℹ 192 more rows\n\n\n\n\n\nlibrary(rtichoke)\n\nsvm_probs &lt;- predict(svm_rbf_fit, \n        new_data = sim_data2_test,\n        type = 'prob') |&gt; \n  pull(.pred_1)\n\nsvm_performance_data &lt;- prepare_performance_data(\n  probs = list(svm_probs),\n  reals = list(sim_data2_test$y == 1)\n)\n\nsvm_performance_data |&gt; \n  select(probability_threshold, specificity, sensitivity)\n\n# A tibble: 101 × 3\n   probability_threshold specificity sensitivity\n                   &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1                  0           0              1\n 2                  0.01        0              1\n 3                  0.02        0              1\n 4                  0.03        0              1\n 5                  0.04        0              1\n 6                  0.05        0              1\n 7                  0.06        0              1\n 8                  0.07        0              1\n 9                  0.08        0.04           1\n10                  0.09        0.06           1\n# ℹ 91 more rows"
  },
  {
    "objectID": "posts/2022-10-02-ROC-for-SVM/index.html#roc-curve",
    "href": "posts/2022-10-02-ROC-for-SVM/index.html#roc-curve",
    "title": "ROC for SVM Model from ISLR",
    "section": "ROC Curve",
    "text": "ROC Curve\n\nyardstickrtichoke\n\n\nyardstick_roc |&gt; \n  autoplot() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nsvm_performance_data |&gt; \n  plot_roc_curve(size = 350)"
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "",
    "text": "Prediction Model might gain accuracy if you’ll add more relevant features to existing models, but many times it’s not obvious what is the additional value of additional feature and how to quantify it in terms of Decision Making. The post Decision curve analysis for quantifying the additional benefit of a new marker by Emily Vertosick and Andrew Vickers show a simple example (the code presented here is almost identical to the original code presented in the link)."
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#additional-benefit-of-a-new-marker",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#additional-benefit-of-a-new-marker",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "",
    "text": "Prediction Model might gain accuracy if you’ll add more relevant features to existing models, but many times it’s not obvious what is the additional value of additional feature and how to quantify it in terms of Decision Making. The post Decision curve analysis for quantifying the additional benefit of a new marker by Emily Vertosick and Andrew Vickers show a simple example (the code presented here is almost identical to the original code presented in the link)."
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#preparing-the-data",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#preparing-the-data",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "Preparing the Data",
    "text": "Preparing the Data\n\nLoading the Data with Hmisc\n\nlibrary(Hmisc)\nlibrary(dplyr)\nlibrary(tibble)\n\ngetHdata(acath)\nacath &lt;- subset(acath, !is.na(choleste))\n\n\n\nFitting Logistic Regressions with rms\n\nlibrary(rms)\n\npre &lt;- lrm(sigdz ~ rcs(age,4) * sex, data = acath)\npre_pred &lt;- predict(pre, type='fitted')\n\npost &lt;- lrm(sigdz ~ rcs(age,4) * sex + \n              rcs(choleste,4) + rcs(age,4) %ia% rcs(choleste,4), data = acath)\npost_pred &lt;- predict(post, type='fitted')\n\nacath_pred &lt;- bind_cols(\n    acath,\n    pre_pred |&gt; enframe(name = NULL, value = \"pre\"),\n    post_pred |&gt; enframe(name = NULL, value = \"post\")\n  )"
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#conventional-decision-curve",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#conventional-decision-curve",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "Conventional Decision Curve",
    "text": "Conventional Decision Curve\n\ndcurvesrtichoke\n\n\nlibrary(dcurves)\n\ndca_prepost &lt;- dca(\n    sigdz ~ pre + post,\n    data = acath_pred,\n    label = list(\n      pre = \"Age and Sex\",\n      post = \"Age, Sex and Cholesterol\"))\n\ndca_prepost |&gt;\n  plot(smooth = TRUE)  + \n  theme_classic()  +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nlibrary(rtichoke)\nlibrary(plotly)\n\nperformance_data_dc &lt;- \n  prepare_performance_data(\n  probs = list(\n    \"Age and Sex\" = \n      acath_pred$pre,\n    \"Age, Sex and Cholesterol\" = \n      acath_pred$post\n  ),\n  reals = list(acath_pred$sigdz)\n)\n\nperformance_data_dc |&gt;\n  plot_decision_curve(\n    color_values = \n      c(\"#00BFC4\", \"#C77CFF\"),\n    size = 350\n  ) |&gt;\n  plotly::layout(\n    yaxis = list(\n      range =\n        c(-0.07, 0.7)\n    )\n  )"
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#specific-range-of-probability-thresholds",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#specific-range-of-probability-thresholds",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "Specific Range of Probability Thresholds",
    "text": "Specific Range of Probability Thresholds\n\ndcurvesrtichoke\n\n\nlibrary(dcurves)\n\ndca_prepost_15_35 &lt;- dca(\n    sigdz ~ pre + post,\n    data = acath_pred,\n    thresholds = seq(0.15, 0.35, by = 0.05),\n    label = list(\n      pre = \"Age and Sex\",\n      post = \"Age, Sex and Cholesterol\")) |&gt;\n  plot(type = 'net_benefit', \n       smooth = FALSE, \n       show_ggplot_code = FALSE)\n\ndca_prepost_15_35 + \n  theme_classic()  + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nperformance_data_dc |&gt; \n  rtichoke::plot_decision_curve(\n    color_values = c(\"#00BFC4\", \"#C77CFF\"),\n    min_p_threshold = 0.15, \n    max_p_threshold = 0.35,\n    size = 350\n  ) |&gt; \n  plotly::layout(\n    yaxis = list(range =\n                   c(-0.07, 0.7))\n  )"
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#interventions-avoided",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#interventions-avoided",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "Interventions Avoided",
    "text": "Interventions Avoided\n\ndcurvesrtichoke\n\n\ndca_prepost |&gt;\n  net_intervention_avoided() |&gt; \n  plot(type = 'net_intervention_avoided', \n       smooth = FALSE)  + \n  theme_classic()  +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nperformance_data_dc |&gt;\n  rtichoke::plot_decision_curve(\n    color_values = c(\"#F8766D\", \"#00BFC4\"),\n    type = \"interventions avoided\",\n    size = 350\n  ) |&gt;\n  plotly::layout(\n    yaxis = list(range =\n                   c(-10, 100))\n  )"
  },
  {
    "objectID": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#conventional-and-interventions-avoided-combined-rtichoke-code",
    "href": "posts/2022-09-18-dca-for-quantifying-the-additional-benefit-of-a-new-marker-by-emily-vertosick-and-andrew-vickers/index.html#conventional-and-interventions-avoided-combined-rtichoke-code",
    "title": "DCA for Quantifying the Additional Benefit of a New Marker by Emily Vertosick and Andrew Vickers",
    "section": "Conventional and Interventions Avoided Combined (rtichoke code)",
    "text": "Conventional and Interventions Avoided Combined (rtichoke code)\nperformance_data_dc |&gt;\n  plot_decision_curve(\n    color_values = \n      c(\"#00BFC4\", \"#C77CFF\"),\n    type = \"combined\",\n    size = 500\n  )"
  },
  {
    "objectID": "posts/2022-08-21-cox-box-transformation/index.html",
    "href": "posts/2022-08-21-cox-box-transformation/index.html",
    "title": "Box-Cox transformation from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "",
    "text": "This blog will be dedicated to the {rtichoke} package, which means that it will contain posts that are related to performance metrics and the possible related usability of {rtichoke}."
  },
  {
    "objectID": "posts/2022-08-21-cox-box-transformation/index.html#welcome-to-rtichoke-blog",
    "href": "posts/2022-08-21-cox-box-transformation/index.html#welcome-to-rtichoke-blog",
    "title": "Box-Cox transformation from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "",
    "text": "This blog will be dedicated to the {rtichoke} package, which means that it will contain posts that are related to performance metrics and the possible related usability of {rtichoke}."
  },
  {
    "objectID": "posts/2022-08-21-cox-box-transformation/index.html#replications",
    "href": "posts/2022-08-21-cox-box-transformation/index.html#replications",
    "title": "Box-Cox transformation from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "Replications",
    "text": "Replications\nTo make the package easier to use I plan to reproduce other people’s code with rtichoke, posts of this kind will be available under the category “replications”.\nMy first choice is to replicate the first example from the book “Feature Engineering and Selection: A Practical Approach for Predictive Models by Max Kuhn and Kjell Johnson”.\nIn this example you can see how Box-Cox transformation improves the discrimination capability of the logistic regression model without using any additional information."
  },
  {
    "objectID": "posts/2022-08-21-cox-box-transformation/index.html#original-code",
    "href": "posts/2022-08-21-cox-box-transformation/index.html#original-code",
    "title": "Box-Cox transformation from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "Original Code",
    "text": "Original Code\nThe code is almost identical to the original code that can be found on github.\n\nPreparing the Data\n\nlibrary(caret)\nlibrary(tidymodels)\nlibrary(ggplot2)\n\n\ndata(segmentationData)\n\nsegmentationData &lt;- \n  segmentationData |&gt; \n  dplyr::select(EqSphereAreaCh1, PerimCh1, Class, Case) |&gt; \n  setNames(c(\"PredictorA\", \"PredictorB\", \"Class\", \"Case\")) |&gt; \n  mutate(Class = factor(ifelse(Class == \"PS\", \"One\", \"Two\")))\n\nexample_train &lt;- \n  segmentationData |&gt; \n  dplyr::filter(Case == \"Train\") |&gt; \n  dplyr::select(-Case)\n\nexample_test  &lt;- \n  segmentationData |&gt; \n  dplyr::filter(Case == \"Test\") |&gt; \n  dplyr::select(-Case)\n\n\n\nTraining the Models\n\nexample_ctrl &lt;- \n  trainControl(method = \"none\",\n               classProbs = TRUE,\n               summaryFunction = twoClassSummary)\n\nnatural_terms &lt;- train(Class ~ PredictorA + PredictorB,\n                       data = example_train,\n                       method = \"glm\",\n                       metric = \"ROC\",\n                       trControl = example_ctrl)\n\ntrans_terms &lt;- train(Class ~ PredictorA + PredictorB,\n                     data = example_train,\n                     method = \"glm\",\n                     preProc = \"BoxCox\",\n                     metric = \"ROC\",\n                     trControl = example_ctrl)\n\n\n\nCreating Predictions\n\noriginal_probs &lt;- predict(natural_terms, example_test, type = \"prob\")[,1]\n\ntransformed_probs &lt;- predict(trans_terms, example_test, type = \"prob\")[,1]\n\noutcomes &lt;- example_test$Class == \"One\"\n\n\n\nCreating ROC Curve with yardstick\n\nnatural_dat &lt;-\n  example_test |&gt; \n  mutate(\n    prob = original_probs) |&gt; \n  roc_curve(Class, prob) |&gt; \n  mutate(Format = \"Natural Units\")\n\ntrans_dat &lt;-\n  example_test |&gt; \n  mutate(\n    prob = transformed_probs) |&gt; \n  roc_curve(Class, prob) |&gt; \n  mutate(Format = \"Inverse Units\") \n\nboth_dat &lt;- \n  bind_rows(natural_dat, trans_dat) |&gt;\n  mutate(\n    Format = factor(Format, levels = c(\"Natural Units\", \"Inverse Units\")))\n\ntrans_roc_plot &lt;- \n  ggplot(both_dat) +\n  geom_step(aes(x = 1 - specificity, y = sensitivity, color = Format)) + \n  coord_equal() + \n  xlab(\"False Positive Rate\") + \n  ylab(\"True Positive Rate\") + \n  theme(legend.position = c(.8, .2)) + \n  scale_colour_manual(\n    values = c(\"Natural Units\" = \"grey\", \n               \"Inverse Units\" = \"black\")) + \n  geom_abline(intercept = 0, slope = 1, col = \"grey\", lty = 2) +\n  theme_classic()\n\ntrans_roc_plot"
  },
  {
    "objectID": "posts/2022-08-21-cox-box-transformation/index.html#rtichoke-code",
    "href": "posts/2022-08-21-cox-box-transformation/index.html#rtichoke-code",
    "title": "Box-Cox transformation from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "rtichoke code",
    "text": "rtichoke code\n\nCreating ROC Curve with rtichoke\n\nBy Probability ThresholdBy Percent Positives Conditional Rate\n\n\nlibrary(rtichoke)\n\ncreate_roc_curve(\n  probs = list(\n    \"Natural Units\" = original_probs,\n    \"Inverse Units\" = transformed_probs\n  ),\n  reals = list(\n    outcomes\n  ),\n  size = 350, \n  color_values = c(\"grey\", \"black\")\n) \n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(rtichoke)\n\ncreate_roc_curve(\n  probs = list(\n    \"Natural Units\" = original_probs,\n    \"Inverse Units\" = transformed_probs\n  ),\n  reals = list(\n    outcomes\n  ),\n  stratified_by = \"ppcr\",\n  size = 350, \n  color_values = c(\"grey\", \"black\")\n)"
  },
  {
    "objectID": "about_me.html",
    "href": "about_me.html",
    "title": "Uriah Finkel",
    "section": "",
    "text": "Author of rtichoke\nData Scientist in Clalit Innovation\nCo-Admin of Israeli R community “R for the Masses”"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to rtichoke blog",
    "section": "",
    "text": "Welcome to rtichoke blog\nThis blog is dedicated to reproducible examples by rtichoke in order to help new users to have a quick start. For more conventional documentation of the package please visit rtichoke pkgdown website.\nSome of the posts will be replications of existing code that produces the same output as rtichoke by different packages.\nOther posts will be more focused on theoretical issues, but always with a reproducible code.\nI will also share some talks that might be about everything as long as there are some relevant outputs by rtichoke (Most of the talks will be in Hebrew but the slides will always be in English)."
  },
  {
    "objectID": "posts/2022-09-04-precision-recall/index.html",
    "href": "posts/2022-09-04-precision-recall/index.html",
    "title": "Precision Recall from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "",
    "text": "Precision Recall Curve is shown as an alternative to the known ROC curve in the “second part from the ‘Measuring Performance’ Chapter of Feature Engineering and Selection”. It is mentioned that this curve is more appropriate in terms of Information Retrieval.\n\n\nThe code is almost identical to the original code that can be found on github.\nAlternatively you can download the caret object from here and load it into the global environment by running the following command:\n\nload(\"okc_glm_keyword.RData\")\n\n\n\n\nROCPrecision Recall\n\n\nlibrary(yardstick)\nlibrary(ggplot2)\nlibrary(magrittr)\n\nglm_keyword$pred  %&gt;% \n  roc_curve(obs, stem) %&gt;% \n  autoplot()  +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nlibrary(yardstick)\nlibrary(ggplot2)\nlibrary(magrittr)\n\nglm_keyword$pred  %&gt;% \n  pr_curve(obs, stem) %&gt;% \n  autoplot()  +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nROCPrecision Recall\n\n\nlibrary(rtichoke)\n\ncreate_roc_curve(\n  probs = list(\n    glm_keyword$pred$stem),\n  reals = list(\n    glm_keyword$pred$obs == \"stem\"),\n  size = 350\n)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(rtichoke)\n\ncreate_precision_recall_curve(\n  probs = list(\n    glm_keyword$pred$stem),\n  reals = list(\n    glm_keyword$pred$obs == \"stem\"),\n  size = 350\n)"
  },
  {
    "objectID": "posts/2022-09-04-precision-recall/index.html#original-code",
    "href": "posts/2022-09-04-precision-recall/index.html#original-code",
    "title": "Precision Recall from Feature Engineering by Max Kuhn and Kjell Johnson",
    "section": "",
    "text": "The code is almost identical to the original code that can be found on github.\nAlternatively you can download the caret object from here and load it into the global environment by running the following command:\n\nload(\"okc_glm_keyword.RData\")\n\n\n\n\nROCPrecision Recall\n\n\nlibrary(yardstick)\nlibrary(ggplot2)\nlibrary(magrittr)\n\nglm_keyword$pred  %&gt;% \n  roc_curve(obs, stem) %&gt;% \n  autoplot()  +\n  theme_classic()\n\n\n\n\n\n\n\n\n\nlibrary(yardstick)\nlibrary(ggplot2)\nlibrary(magrittr)\n\nglm_keyword$pred  %&gt;% \n  pr_curve(obs, stem) %&gt;% \n  autoplot()  +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nROCPrecision Recall\n\n\nlibrary(rtichoke)\n\ncreate_roc_curve(\n  probs = list(\n    glm_keyword$pred$stem),\n  reals = list(\n    glm_keyword$pred$obs == \"stem\"),\n  size = 350\n)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(rtichoke)\n\ncreate_precision_recall_curve(\n  probs = list(\n    glm_keyword$pred$stem),\n  reals = list(\n    glm_keyword$pred$obs == \"stem\"),\n  size = 350\n)"
  }
]